I designed a way and built a tool to analyse robustness of graph metrics by evaluating them on many generated graphs.

\section{Motivation}

This project was inspired by, and is based on the following paper~\cite{Bozhilova2019} (further referred to as ``The Paper'') which served as a kickoff point for this project.
\begin{adjustwidth}{1cm}{}
    \vspace*{0.5em}
    Bozhilova, L. V., Whitmore, A. V., Wray, J., Reinert, G., \& Deane, C. M. (2019). Measuring rank robustness in scored protein interaction networks. BMC Bioinformatics, 20(1). \url{https://doi.org/10.1186/s12859-019-3036-6}
    \vspace*{0.5em}
\end{adjustwidth}

Graph metrics are often used to find and derive facts about important nodes or components of networks.
However, real-world datasets may be inherently imprecise, or the procedure of obtaining networks from raw measured data may introduce (sometimes invisible) inaccuracies.
When evaluating graph metrics on imprecise data, it is crucial to be able to reason about the reliability and of the results, as with any other statistical procedures.

The Paper introduces ways to assess \textsl{robustness} of graph metrics specifically on protein interaction networks with confidence-scored edges.

I built a tool that can measure robustness of graph metrics on any graph dataset, extending the idea from The Paper to networks with unweighted edges.

\section{Graphs}

%The total data (created, captured or replicated) in the world by 2018 was estimated to be 18 zettabytes in 2018 and is expected to reach 175 zettabytes by 2025~\cite{ReinselDigitizationWorldEdge2018}.
Ever-increasing data sources and applications of data science force researchers and data scientists to use tools such as graph theory to model real-world problems.
Graphs, or networks (nodes and edges), can capture many types of entities and their relations in the real world.
Graph theory, believed to have been invented by L. Euler in 18th century~\cite{BiggsGraphTheory173619361986} has been since used to help solve problems in the field of information technology, engineering, biology, chemistry, social systems, geography, linguistics and many more ~\cite{FouldsGraphTheoryApplications2012}.
A simple example is a social network in which nodes may represent people and edges represent existence of relationships between pairs of people.


\section{Graph metrics}

Graph theory proved especially useful when analysing large structures of data that cannot simply be visualised or otherwise analysed by investigating individual entities.
The word \textsl{network} is often used in this context to refer to large instances of graphs stemming from real systems, as opposed to graphs referring more to the mathematical concept itself.
Graph \textsl{statistics} (e.g. size, average degree, diameter, radius) have been invented to help mathematically describe properties of arbitrarily large graphs, such as betweenness centrality.
Further, graph \textsl{metrics} (such as betweenness centrality, closeness centrality, eccentricity) quantify properties of individual nodes.
For example a person represented by a node with high closeness centrality score is considered to be \textsl{closer} to others in terms of number of hops needed, in other words can spread information in the network faster.

Protein interaction networks is an example of a prominent research field relying on graph theory.
Nodes in protein networks represent proteins present in cells of organisms and edges represent interactions between them, possibly labelled to convey additional information.
Studying such networks helps in understanding physiology of biological cells and developing drugs as they generally affect protein interactions.


\section{Imperfect data}

The problem is, networks constructed from real-world contain errors such as missing nodes or edges, false positives, uncertain nodes or edges, falsely aggregated nodes.
Network errors may stem from measurement errors, approximations, lack of knowledge, lack of experimental evidence or thresholding of scored networks~\cite{Wang2012,MarsdenNetworkDataMeasurement1990,JonesChallengesLimitationsQuantifying2010}.
These errors may then propagate and cause errors in graph metrics, which the user of the dataset may not be aware of. \todo{clarify}

For example, the STRING database\cite{Szklarczyk2019} is an open collection that contains known and predicted protein-protein interactions.
It provides confidence scores for edges, indicating how likely the dataset authors consider an interaction to be true, given the available evidence.
The Paper~\cite{Bozhilova2019} demonstrates instability of some graph metrics on thresholded protein networks and proposes ways to assess robustness of graph metrics in such networks.


\section{Metric robustness}

Although the field of investigating graph metric robustness is novel and recent, a number of attempts tried to assess robustness or stability properties of graph metrics.
Examples are analysing impact of errors on centrality measures in random networks~\cite{BorgattiRobustnessCentralityMeasures2006} or, more specifically, evaluating reproducibility of metrics on multi-temporal scans of human brain using coefficient of variation (CV), the repeatability coefficient (RC) and the intra class correlation (ICC)~\cite{VaessenEffectReproducibilityDifferent2010,DennisTestRetestReliabilityGraph2012}.
A significant amount of research analysing reproducibility of metrics in uncertain brain networks appeared around 2011, summarised in~\cite{TelesfordExplorationGraphMetric2013}.
The latest research led to development of methods for analysis of such uncertain data, estimating a ground-truth network structure from imperfect data~\cite{Martin2016,Newman2018}, and even a method to mitigate sensitivity of metrics on the selection of a threshold in scored networks~\cite{Drakesmith2015}.

One of the most recent researches on metric robustness is already mentioned work on protein interaction networks in The Paper.
In the study they use 3 ways to quantify metric robustness, focusing on comparing node rankings induced by each metric at different score thresholds instead of the calculated values, arguing that comparing ranks better assesses robustness of metrics.
Those robustness measures are: Rank continuity (comparing sets of highly ranked nodes between graphs derived from similar confidence threshold), Rank identifiability (considering overall ranks of all nodes and quantifying how much these ranks differ from ranks observed in graphs derived from various confidence thresholds), Rank instability (quantifying variation of ranks of top 1\% of nodes over a certain confidence range).


\section{Software tool: \graffs}

\todo{revise once done}

In this dissertation I summarise the research done on this topic and build a command-line tool that helps generalise the research of graph metric robustness and allows application of the above mentioned methods to graphs of other kinds.
\Cref{ch:preparation} explains The Paper in more detail, revises the background material and proposes the method used in the framework.

First, I generalise graph acquisition using different methods on different source datasets, such as edge score thresholding or random edge removal.
Consequently, the framework applies a number of robustness measures on some of the most common node-level graph metrics, and tries to infer any correlation between graph classes and robustness of metrics used on them.
\Cref{ch:implementation} describes the framework implementation of the framework, which I then evaluate in \cref{ch:evaluation}.

\todo{describe evaluation?}


I wrapped up the project named \graffs and published it as an open-source library that can further be used by future projects in this research area.
