I designed a way and built a tool to analyse robustness of graph metrics by evaluating them on many generated graphs.

This project was inspired by, and is based on the following paper~\cite{Bozhilova2019} (further referred to as ``The Paper'') which served as a kickoff point for this project.
\begin{adjustwidth}{1cm}{}
    \vspace*{0.5em}\fullcite{Bozhilova2019}\vspace*{0.5em}
\end{adjustwidth}

Graph metrics are often used to find and derive facts about important nodes or components of networks.
However, real-world datasets may be inherently imprecise, or the procedure of obtaining networks from raw measured data may introduce (sometimes invisible) inaccuracies.
When evaluating graph metrics on imprecise data, it is crucial to be able to reason about the reliability and of the results, as with any other statistical procedures.
The field of examining stability and reliability of graph metrics is relatively novel.

The Paper introduces ways to assess \textsl{robustness} of graph metrics specifically on protein interaction networks with confidence-scored edges.
In this dissertation I summarise the research done on this topic and build a command-line tool that helps generalise the research of graph metric robustness and enables similar experiments on graphs of other kinds.

The goals of my work are:
\begin{enumerate}
    \item To implement a tool called \graffs to automate the kind of experiments done in The Paper
    \item To reproduce a subset of results from The Paper
    \item To extend the idea of graph metric robustness on unscored networks
\end{enumerate}

I wrapped up the project and published it as an open-source library that can further be used by future projects in this research area.

\subsubsection*{Structure}

\todo{revise once done}

\Cref{ch:preparation} explains The Paper in more detail, revises the background material and explains method used in \graffs.

First, I generalise graph acquisition using different methods on different source datasets, such as edge score thresholding or random edge removal.
Consequently, the framework applies a number of robustness measures on some of the most common node-level graph metrics, and tries to infer any correlation between graph classes and robustness of metrics used on them.
\Cref{ch:implementation} describes the framework implementation of the framework, which I then evaluate in \cref{ch:evaluation}.

\todo{briefly describe evaluation?}

